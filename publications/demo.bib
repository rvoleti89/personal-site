
@inproceedings{VoletiObjectiveAssessmentSocial2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1904.10622},
  address = {Graz, Austria},
  title = {Objective {{Assessment}} of {{Social Skills Using Automated Language Analysis}} for {{Identification}} of {{Schizophrenia}} and {{Bipolar Disorder}}},
  copyright = {All rights reserved},
  abstract = {Several studies have shown that speech and language features, automatically extracted from clinical interviews or spontaneous discourse, have diagnostic value for mental disorders such as schizophrenia and bipolar disorder. They typically make use of a large feature set to train a classifier for distinguishing between two groups of interest, i.e. a clinical and control group. However, a purely data-driven approach runs the risk of overfitting to a particular data set, especially when sample sizes are limited. Here, we first down-select the set of language features to a small subset that is related to a well-validated test of functional ability, the Social Skills Performance Assessment (SSPA). This helps establish the concurrent validity of the selected features. We use only these features to train a simple classifier to distinguish between groups of interest. Linear regression reveals that a subset of language features can effectively model the SSPA, with a correlation coefficient of 0.75. Furthermore, the same feature set can be used to build a strong binary classifier to distinguish between healthy controls and a clinical group (AUC = 0.96) and also between patients within the clinical group with schizophrenia and bipolar I disorder (AUC = 0.83).},
  booktitle = {{{INTERSPEECH}} 2019 ({{Under Review}} + Pre-Print Available)},
  publisher = {{ISCA}},
  author = {Voleti, Rohit and Woolridge, Stephanie and Liss, Julie M. and Milanovic, Melissa and Bowie, Christopher R. and Berisha, Visar},
  month = apr,
  year = {2019},
  keywords = {Computer Science - Computation and Language},
  file = {C:\\Users\\rvole\\Zotero\\storage\\6H5A26HY\\Voleti et al_2019_Objective Assessment of Social Skills Using Automated Language Analysis for.pdf;C:\\Users\\rvole\\Zotero\\storage\\EHIWHC4B\\1904.html},
  annote = {Comment: Submitted to INTERSPEECH 2019 (under review). 4 pages + 1 page references. Two figures}
}

@article{MuztobaInstinctiveAssistiveIndoor2018,
  title = {Instinctive {{Assistive Indoor Navigation}} Using {{Distributed Intelligence}}},
  volume = {23},
  copyright = {All rights reserved},
  issn = {10844309},
  language = {en},
  number = {6},
  journal = {ACM Transactions on Design Automation of Electronic Systems},
  doi = {10.1145/3212720},
  author = {Muztoba, Md and Voleti, Rohit and Karabacak, Fatih and Park, Jaehyun and Ogras, Umit Y.},
  month = nov,
  year = {2018},
  pages = {1-21}
}

@inproceedings{VoletiInvestigatingEffectsWord2019,
  title = {Investigating the {{Effects}} of {{Word Substitution Errors}} on {{Sentence Embeddings}}},
  copyright = {All rights reserved},
  abstract = {A key initial step in several natural language processing (NLP) tasks involves embedding phrases of text to vectors of real numbers that preserve semantic meaning. To that end, several methods have been recently proposed with impressive results on semantic similarity tasks. However, all of these approaches assume that perfect transcripts are available when generating the embeddings. While this is a reasonable assumption for analysis of written text, it is limiting for analysis of transcribed text. In this paper we investigate the effects of word substitution errors, such as those coming from automatic speech recognition errors (ASR), on several state-of-the-art sentence embedding methods. To do this, we propose a new simulator that allows the experimenter to induce ASR-plausible word substitution errors in a corpus at a desired word error rate. We use this simulator to evaluate the robustness of several sentence embedding methods. Our results show that pre-trained neural sentence encoders are both robust to ASR errors and perform well on textual similarity tasks after errors are introduced. Meanwhile, unweighted averages of word vectors perform well with perfect transcriptions, but their performance degrades rapidly on textual similarity tasks for text with word substitution errors.},
  booktitle = {{{ICASSP}} 2019 - 2019 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  doi = {10.1109/ICASSP.2019.8683367},
  author = {Voleti, R. and Liss, J. M. and Berisha, V.},
  month = may,
  year = {2019},
  keywords = {ASR Error Simulator,Natural Language Processing,Semantic Embedding,Sentence Embeddings,Speech Recognition},
  pages = {7315-7319},
  file = {C:\\Users\\rvole\\Zotero\\storage\\C326NCFA\\Voleti et al_2019_Investigating the Effects of Word Substitution Errors on Sentence Embeddings.pdf;C:\\Users\\rvole\\Zotero\\storage\\JCVRKGJZ\\8683367.html}
}


